#!/usr/bin/env python3
"""
Script pour indexer le contenu des n≈ìuds Page avec Neo4j Vector Index.
- Utilise un embedding open source (SentenceTransformers) au lieu d'OpenAI
- Indexe la propri√©t√© markdown_content des n≈ìuds Page
- Cr√©e un index vectoriel pour la recherche de similarit√©
"""

import os
from typing import Dict, Any, Optional

from dotenv import load_dotenv
from neo4j import GraphDatabase

# LangChain imports
from langchain_neo4j import Neo4jVector
from langchain_huggingface import HuggingFaceEmbeddings

# --- Configuration ---
load_dotenv()

# Neo4j Configuration
NEO4J_URI = os.getenv("NEO4J_URI", "bolt://localhost:7689")
NEO4J_USER = os.getenv("NEO4J_USER", "neo4j")
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD", "password123")

# Configuration de l'embedding
# Utilisation d'un mod√®le open source multilingue pour supporter l'allemand
EMBEDDING_MODEL_NAME = os.getenv("EMBEDDING_MODEL_NAME", "Qwen/Qwen3-Embedding-0.6B")
EMBEDDING_MODEL_KWARGS = {"device": "cpu"}  # Utiliser "cuda" si GPU disponible
EMBED_ENCODE_KWARGS = {"normalize_embeddings": True}  # Normaliser pour la similarit√© cosinus

# Configuration de l'index vectoriel
VECTOR_INDEX_NAME = os.getenv("VECTOR_INDEX_NAME", "page_vector_qwen_index")
KEYWORD_INDEX_NAME = os.getenv("KEYWORD_INDEX_NAME", "page_keyword")  # Index de mots-cl√©s sp√©cifique aux Pages
EMBEDDING_NODE_PROPERTY = "embedding_qwen"  # Nom de la propri√©t√© o√π stocker l'embedding

class PageIndexer:
    """Gestionnaire pour indexer les pages avec Neo4j Vector Index"""
    
    def __init__(self, uri: str, user: str, password: str):
        self.driver = None
        self.embeddings = None
        self.vector_store = None
        
        try:
            self.driver = GraphDatabase.driver(uri, auth=(user, password))
            self.driver.verify_connectivity()
            print(f"‚úì Connexion √† Neo4j √©tablie: {uri}")
        except Exception as e:
            print(f"‚ö†Ô∏è  Erreur de connexion √† Neo4j: {e}")
            raise
        
        # Initialiser l'embedding open source
        try:
            print(f"üì¶ Chargement du mod√®le d'embedding: {EMBEDDING_MODEL_NAME}")
            self.embeddings = HuggingFaceEmbeddings(
                model_name=EMBEDDING_MODEL_NAME,
                model_kwargs=EMBEDDING_MODEL_KWARGS,
                encode_kwargs=EMBED_ENCODE_KWARGS
            )
            print(f"‚úì Mod√®le d'embedding charg√©")
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement du mod√®le d'embedding: {e}")
            raise
    
    def check_page_nodes(self) -> Dict[str, Any]:
        """V√©rifie les n≈ìuds Page disponibles"""
        if not self.driver:
            return {}
        
        try:
            with self.driver.session() as session:
                result = session.run("""
                    MATCH (p:Page)
                    WHERE p.markdown_content IS NOT NULL 
                    AND p.markdown_content <> ""
                    RETURN 
                        count(p) as total_page_nodes,
                        count(DISTINCT p.url) as total_sources,
                        avg(size(p.markdown_content)) as avg_content_length,
                        count(CASE WHEN p.embedding_qwen IS NOT NULL THEN 1 END) as already_indexed
                """)
                record = result.single()
                return {
                    'total_page_nodes': record['total_page_nodes'],
                    'total_sources': record['total_sources'],
                    'avg_content_length': round(record['avg_content_length'], 2) if record['avg_content_length'] else 0,
                    'already_indexed': record['already_indexed']
                }
        except Exception as e:
            print(f"‚ùå Erreur lors de la v√©rification des n≈ìuds Page: {e}")
            return {}
    
    def index_pages(self) -> Dict[str, Any]:
        """
        Indexe le contenu des n≈ìuds Page en utilisant Neo4jVector.from_existing_graph.
        Cette m√©thode lit les n≈ìuds Page existants, calcule les embeddings et les stocke.
        """
        if not self.driver or not self.embeddings:
            return {"indexed": 0, "errors": 0}
        
        stats = {"indexed": 0, "errors": 0}
        
        try:
            print(f"üîç Indexation des n≈ìuds Page avec l'index: {VECTOR_INDEX_NAME}")
            print(f"   Propri√©t√© de texte: markdown_content")
            print(f"   Propri√©t√© d'embedding: {EMBEDDING_NODE_PROPERTY}")
            
            # Utiliser from_existing_graph pour indexer les n≈ìuds Page existants
            # Cette m√©thode:
            # 1. Lit les n≈ìuds Page avec markdown_content
            # 2. Calcule les embeddings pour chaque markdown_content
            # 3. Stocke les embeddings dans la propri√©t√© embedding_node_property
            # 4. Cr√©e un index vectoriel Neo4j
            # Note: Utiliser un index de mots-cl√©s sp√©cifique pour √©viter les conflits
            self.vector_store = Neo4jVector.from_existing_graph(
                embedding=self.embeddings,
                url=NEO4J_URI,
                username=NEO4J_USER,
                password=NEO4J_PASSWORD,
                index_name=VECTOR_INDEX_NAME,
                keyword_index_name=KEYWORD_INDEX_NAME,  # Index de mots-cl√©s sp√©cifique aux Pages
                search_type="hybrid",
                node_label="Page",
                text_node_properties=["markdown_content"],  # Propri√©t√© √† indexer
                embedding_node_property=EMBEDDING_NODE_PROPERTY,  # O√π stocker l'embedding
            )
            
            # V√©rifier combien de n≈ìuds ont √©t√© index√©s
            page_stats = self.check_page_nodes()
            stats["indexed"] = page_stats.get("already_indexed", 0)
            
            print(f"‚úì Index vectoriel cr√©√© avec succ√®s")
            print(f"‚úì {stats['indexed']} n≈ìuds Page index√©s")
            
        except Exception as e:
            print(f"‚ùå Erreur lors de l'indexation: {e}")
            stats["errors"] = 1
            import traceback
            traceback.print_exc()
        
        return stats
    
    def test_similarity_search(self, query: str = "Studium", k: int = 3) -> list:
        """Teste la recherche de similarit√© avec une requ√™te"""
        if not self.vector_store:
            print("‚ö†Ô∏è  L'index vectoriel n'est pas initialis√©")
            return []
        
        try:
            print(f"\nüîç Test de recherche de similarit√©:")
            print(f"   Requ√™te: '{query}'")
            print(f"   Nombre de r√©sultats: {k}")
            
            results = self.vector_store.similarity_search(query, k=k)
            
            print(f"\n‚úì {len(results)} r√©sultats trouv√©s:")
            for i, doc in enumerate(results, 1):
                print(f"\n--- R√©sultat {i} ---")
                # Extraire le contenu et les m√©tadonn√©es
                content = doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content
                print(f"Contenu: {content}")
                if doc.metadata:
                    print(f"M√©tadonn√©es: {doc.metadata}")
            
            return results
            
        except Exception as e:
            print(f"‚ùå Erreur lors de la recherche de similarit√©: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def get_index_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques de l'index vectoriel"""
        if not self.driver:
            return {}
        
        try:
            with self.driver.session() as session:
                # V√©rifier si l'index existe
                index_check = session.run("""
                    SHOW INDEXES
                    YIELD name, type, state, populationPercent
                    WHERE name = $index_name
                    RETURN name, type, state, populationPercent
                """, index_name=VECTOR_INDEX_NAME)
                
                index_info = index_check.single()
                
                # Statistiques des n≈ìuds index√©s
                page_stats = self.check_page_nodes()
                
                return {
                    'index_name': index_info['name'] if index_info else None,
                    'index_type': index_info['type'] if index_info else None,
                    'index_state': index_info['state'] if index_info else None,
                    'population_percent': index_info['populationPercent'] if index_info else None,
                    **page_stats
                }
        except Exception as e:
            print(f"‚ùå Erreur lors de la r√©cup√©ration des stats: {e}")
            return {}
    
    def close(self):
        """Ferme la connexion √† Neo4j"""
        if self.driver:
            self.driver.close()
            print("‚úì Connexion Neo4j ferm√©e")

def main():
    """Fonction principale"""
    print("=" * 70)
    print("FH-SWF Page Indexer - Indexation vectorielle avec Neo4j")
    print("=" * 70)
    print(f"Neo4j URI:           {NEO4J_URI}")
    print(f"Neo4j User:           {NEO4J_USER}")
    print(f"Mod√®le d'embedding:  {EMBEDDING_MODEL_NAME}")
    print(f"Index vectoriel:     {VECTOR_INDEX_NAME}")
    print(f"Propri√©t√© texte:     markdown_content")
    print(f"Propri√©t√© embedding: {EMBEDDING_NODE_PROPERTY}")
    print("=" * 70)
    
    try:
        # Initialiser l'indexeur
        indexer = PageIndexer(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)
        
        # V√©rifier les n≈ìuds Page disponibles
        print("\nüìä V√©rification des n≈ìuds Page...")
        page_stats = indexer.check_page_nodes()
        if page_stats:
            print(f"‚úì N≈ìuds Page disponibles: {page_stats.get('total_page_nodes', 0)}")
            print(f"‚úì Sources distinctes: {page_stats.get('total_sources', 0)}")
            print(f"‚úì Taille moyenne du contenu: {page_stats.get('avg_content_length', 0)} caract√®res")
            print(f"‚úì D√©j√† index√©s: {page_stats.get('already_indexed', 0)}")
        
        if page_stats.get('total_page_nodes', 0) == 0:
            print("\n‚ö†Ô∏è  Aucun n≈ìud Page trouv√©. Ex√©cutez d'abord 001_crawl_to_db.py")
            indexer.close()
            return 1
        
        # Indexer les pages
        print("\nüîç Indexation des pages...")
        index_stats = indexer.index_pages()
        
        if index_stats.get("errors", 0) > 0:
            print(f"‚ùå Erreurs lors de l'indexation: {index_stats['errors']}")
        else:
            print(f"‚úì Indexation termin√©e avec succ√®s")
        
        # Afficher les statistiques de l'index
        print("\n" + "=" * 70)
        print("üìä STATISTIQUES DE L'INDEX")
        print("=" * 70)
        
        index_stats_final = indexer.get_index_stats()
        if index_stats_final:
            if index_stats_final.get('index_name'):
                print(f"Nom de l'index:        {index_stats_final.get('index_name')}")
                print(f"Type:                  {index_stats_final.get('index_type')}")
                print(f"√âtat:                  {index_stats_final.get('index_state')}")
                if index_stats_final.get('population_percent') is not None:
                    print(f"Population:            {index_stats_final.get('population_percent')}%")
            print(f"N≈ìuds index√©s:          {index_stats_final.get('already_indexed', 0)}")
            print(f"Total n≈ìuds Page:       {index_stats_final.get('total_page_nodes', 0)}")
            print(f"Sources distinctes:     {index_stats_final.get('total_sources', 0)}")
        
        # Test de recherche de similarit√©
        print("\n" + "=" * 70)
        print("üß™ TEST DE RECHERCHE DE SIMILARIT√â")
        print("=" * 70)
        
        test_query = "Studium"
        indexer.test_similarity_search(test_query, k=3)
        
        print("\n" + "=" * 70)
        print("‚úÖ Indexation termin√©e avec succ√®s!")
        print("=" * 70)
        
        indexer.close()
        
    except Exception as e:
        print(f"‚ùå Erreur fatale: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())

